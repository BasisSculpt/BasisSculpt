Version tag: prec64_original_BEx
Fixed basis name: cc-pVDZ
Selected math precision: 64 digits
-----------------
Atom: H     0
-----------------
  Block type: S
  Header: 4   1.00
    1.301000D+01           1.968500D-02
    1.962000D+00           1.379770D-01
    4.446000D-01           4.781480D-01
    1.220000D-01           5.012400D-01
Full norm: 1.0000009981
Removed # 1 (alfa = 13.0100000000): norm = 0.9909191488, loss = 0.9082%, contribution = 18.5385%
Removed # 2 (alfa = 1.9620000000): norm = 0.8432223682, loss = 15.6778%, contribution = 31.4458%
Removed # 3 (alfa = 0.4446000000): norm = 0.3198386114, loss = 68.0162%, contribution = 35.7908%
Removed # 4 (alfa = 0.1220000000): norm = 0.3453140313, loss = 65.4686%, contribution = 14.2248%
----------------------
Full norm after normalization: 1.0000000000
      1.301000D+01           1.968499D-02
      1.962000D+00           1.379769D-01
      4.446000D-01           4.781478D-01
      1.220000D-01           5.012397D-01
----------------------
  Block type: S
  Header: 1   1.00
    1.220000D-01           1.000000D+00
Only one primitive - nothing to reduce.
----------------------
Full norm after normalization: 1.0000000000
      1.220000D-01           1.000000D+00
----------------------
  Block type: P
  Header: 1   1.00
    7.270000D-01           1.0000000
Only one primitive - nothing to reduce.
----------------------
Full norm after normalization: 1.0000000000
      7.270000D-01           1.000000D+00
----------------------
ALL joined
1.301000D+01           1.968500D-02
1.962000D+00           1.379770D-01
4.446000D-01           4.781480D-01
1.220000D-01           5.012400D-01
1.220000D-01           1.000000D+00
7.270000D-01           1.0000000

Full norm: 7.7288664106
Removed # 1 (alfa = 13.0100000000): norm = 7.7046796911, loss = 0.3129%, contribution = 7.8348%
Removed # 2 (alfa = 1.9620000000): norm = 7.2522737461, loss = 6.1664%, contribution = 13.2897%
Removed # 3 (alfa = 0.4446000000): norm = 5.4215854193, loss = 29.8528%, contribution = 15.1260%
Removed # 4 (alfa = 0.1220000000): norm = 5.4826119695, loss = 29.0632%, contribution = 6.0117%
Removed # 5 (alfa = 0.1220000000): norm = 3.7462313508, loss = 51.5294%, contribution = 11.9937%
Removed # 6 (alfa = 0.7270000000): norm = 3.8073755715, loss = 50.7382%, contribution = 45.7441%
-----------------
-----------------
Atom: C     0
-----------------
  Block type: S
  Header: 9   1.00
    6.665000D+03           6.920000D-04
    1.000000D+03           5.329000D-03
    2.280000D+02           2.707700D-02
    6.471000D+01           1.017180D-01
    2.106000D+01           2.747400D-01
    7.495000D+00           4.485640D-01
    2.797000D+00           2.850740D-01
    5.215000D-01           1.520400D-02
    1.596000D-01          -3.191000D-03
Full norm: 0.9999994819
Removed # 1 (alfa = 6665.0000000000): norm = 0.9999464252, loss = 0.0053%, contribution = 4.7585%
Removed # 2 (alfa = 1000.0000000000): norm = 0.9985210866, loss = 0.1478%, contribution = 8.8341%
Removed # 3 (alfa = 228.0000000000): norm = 0.9820642278, loss = 1.7935%, contribution = 14.8105%
Removed # 4 (alfa = 64.7100000000): norm = 0.8821969242, loss = 11.7803%, contribution = 21.6343%
Removed # 5 (alfa = 21.0600000000): norm = 0.5876494903, loss = 41.2350%, contribution = 25.1787%
Removed # 6 (alfa = 7.4950000000): norm = 0.3275278525, loss = 67.2472%, contribution = 18.9417%
Removed # 7 (alfa = 2.7970000000): norm = 0.6021401677, loss = 39.7860%, contribution = 5.7477%
Removed # 8 (alfa = 0.5215000000): norm = 0.9880555459, loss = 1.1944%, contribution = 0.0870%
Removed # 9 (alfa = 0.1596000000): norm = 1.0012035048, loss = -0.1204%, contribution = 0.0075%
----------------------
Full norm after normalization: 1.0000000000
      6.665000D+03           6.920000D-04
      1.000000D+03           5.329000D-03
      2.280000D+02           2.707700D-02
      6.471000D+01           1.017180D-01
      2.106000D+01           2.747400D-01
      7.495000D+00           4.485640D-01
      2.797000D+00           2.850740D-01
      5.215000D-01           1.520400D-02
      1.596000D-01          -3.189615D-03
----------------------
  Block type: S
  Header: 9   1.00
    6.665000D+03          -1.460000D-04
    1.000000D+03          -1.154000D-03
    2.280000D+02          -5.725000D-03
    6.471000D+01          -2.331200D-02
    2.106000D+01          -6.395500D-02
    7.495000D+00          -1.499810D-01
    2.797000D+00          -1.272620D-01
    5.215000D-01           5.445290D-01
    1.596000D-01           5.804960D-01
Full norm: 0.9999990950
Removed # 1 (alfa = 6665.0000000000): norm = 0.9999967131, loss = 0.0002%, contribution = 3.3191%
Removed # 2 (alfa = 1000.0000000000): norm = 0.9999312858, loss = 0.0068%, contribution = 6.3244%
Removed # 3 (alfa = 228.0000000000): norm = 0.9992093637, loss = 0.0790%, contribution = 10.3523%
Removed # 4 (alfa = 64.7100000000): norm = 0.9947818215, loss = 0.5217%, contribution = 16.3915%
Removed # 5 (alfa = 21.0600000000): norm = 0.9861515617, loss = 1.3848%, contribution = 19.3767%
Removed # 6 (alfa = 7.4950000000): norm = 1.0090989038, loss = -0.9100%, contribution = 20.9376%
Removed # 7 (alfa = 2.7970000000): norm = 1.0726732915, loss = -7.2674%, contribution = 8.4826%
Removed # 8 (alfa = 0.5215000000): norm = 0.3671558384, loss = 63.2844%, contribution = 10.2985%
Removed # 9 (alfa = 0.1596000000): norm = 0.2478400129, loss = 75.2160%, contribution = 4.5174%
----------------------
Full norm after normalization: 1.0000000000
      6.665000D+03          -1.459929D-04
      1.000000D+03          -1.153944D-03
      2.280000D+02          -5.724720D-03
      6.471000D+01          -2.331086D-02
      2.106000D+01          -6.395187D-02
      7.495000D+00          -1.499737D-01
      2.797000D+00          -1.272558D-01
      5.215000D-01           5.445290D-01
      1.596000D-01           5.804960D-01
----------------------
  Block type: S
  Header: 1   1.00
    1.596000D-01           1.000000D+00
Only one primitive - nothing to reduce.
----------------------
Full norm after normalization: 1.0000000000
      1.596000D-01           1.000000D+00
----------------------
  Block type: P
  Header: 4   1.00
    9.439000D+00           3.810900D-02
    2.002000D+00           2.094800D-01
    5.456000D-01           5.085570D-01
    1.517000D-01           4.688420D-01
Full norm: 1.1383912782
Removed # 1 (alfa = 9.4390000000): norm = 1.1100286569, loss = 2.4915%, contribution = 20.6336%
Removed # 2 (alfa = 2.0020000000): norm = 0.8536719893, loss = 25.0107%, contribution = 35.4482%
Removed # 3 (alfa = 0.5456000000): norm = 0.3520901954, loss = 69.0712%, contribution = 32.4600%
Removed # 4 (alfa = 0.1517000000): norm = 0.4847688886, loss = 57.4163%, contribution = 11.4583%
----------------------
Full norm after normalization: 1.0000000000
      9.439000D+00           3.571756D-02
      2.002000D+00           1.963346D-01
      5.456000D-01           4.766437D-01
      1.517000D-01           4.394209D-01
----------------------
  Block type: P
  Header: 1   1.00
    1.517000D-01           1.000000D+00
Only one primitive - nothing to reduce.
----------------------
Full norm after normalization: 1.0000000000
      1.517000D-01           1.000000D+00
----------------------
  Block type: D
  Header: 1   1.00
    5.500000D-01           1.0000000
Only one primitive - nothing to reduce.
----------------------
Full norm after normalization: 1.0000000000
      5.500000D-01           1.000000D+00
----------------------
ALL joined
6.665000D+03           6.920000D-04
1.000000D+03           5.329000D-03
2.280000D+02           2.707700D-02
6.471000D+01           1.017180D-01
2.106000D+01           2.747400D-01
7.495000D+00           4.485640D-01
2.797000D+00           2.850740D-01
5.215000D-01           1.520400D-02
1.596000D-01          -3.191000D-03
6.665000D+03          -1.460000D-04
1.000000D+03          -1.154000D-03
2.280000D+02          -5.725000D-03
6.471000D+01          -2.331200D-02
2.106000D+01          -6.395500D-02
7.495000D+00          -1.499810D-01
2.797000D+00          -1.272620D-01
5.215000D-01           5.445290D-01
1.596000D-01           5.804960D-01
1.596000D-01           1.000000D+00
9.439000D+00           3.810900D-02
2.002000D+00           2.094800D-01
5.456000D-01           5.085570D-01
1.517000D-01           4.688420D-01
1.517000D-01           1.000000D+00
5.500000D-01           1.0000000

Full norm: 26.7849509461
Removed # 1 (alfa = 6665.0000000000): norm = 26.7848979868, loss = 0.0002%, contribution = 3.1704%
Removed # 2 (alfa = 1000.0000000000): norm = 26.7834317760, loss = 0.0057%, contribution = 5.8857%
Removed # 3 (alfa = 228.0000000000): norm = 26.7654027431, loss = 0.0730%, contribution = 9.8675%
Removed # 4 (alfa = 64.7100000000): norm = 26.6403085482, loss = 0.5400%, contribution = 14.4138%
Removed # 5 (alfa = 21.0600000000): norm = 26.1408411578, loss = 2.4047%, contribution = 16.7753%
Removed # 6 (alfa = 7.4950000000): norm = 25.1646328094, loss = 6.0494%, contribution = 12.6199%
Removed # 7 (alfa = 2.7970000000): norm = 25.1596778161, loss = 6.0679%, contribution = 3.8294%
Removed # 8 (alfa = 0.5215000000): norm = 26.6383942875, loss = 0.5472%, contribution = 0.0579%
Removed # 9 (alfa = 0.1596000000): norm = 26.8157855565, loss = -0.1151%, contribution = 0.0050%
Removed #10 (alfa = 6665.0000000000): norm = 26.7849622420, loss = -0.0000%, contribution = 0.6689%
Removed #11 (alfa = 1000.0000000000): norm = 26.7852874053, loss = -0.0013%, contribution = 1.2746%
Removed #12 (alfa = 228.0000000000): norm = 26.7892718935, loss = -0.0161%, contribution = 2.0863%
Removed #13 (alfa = 64.7100000000): norm = 26.8210151724, loss = -0.1346%, contribution = 3.3034%
Removed #14 (alfa = 21.0600000000): norm = 26.9565504593, loss = -0.6407%, contribution = 3.9050%
Removed #15 (alfa = 7.4950000000): norm = 27.4164877929, loss = -2.3578%, contribution = 4.2196%
Removed #16 (alfa = 2.7970000000): norm = 27.5629758900, loss = -2.9047%, contribution = 1.7095%
Removed #17 (alfa = 0.5215000000): norm = 21.8242788134, loss = 18.5204%, contribution = 2.0755%
Removed #18 (alfa = 0.1596000000): norm = 21.5144501774, loss = 19.6771%, contribution = 0.9104%
Removed #19 (alfa = 0.1596000000): norm = 18.1251490145, loss = 32.3308%, contribution = 1.5683%
Removed #20 (alfa = 9.4390000000): norm = 26.6456196875, loss = 0.5202%, contribution = 1.2746%
Removed #21 (alfa = 2.0020000000): norm = 25.4120202901, loss = 5.1258%, contribution = 2.1897%
Removed #22 (alfa = 0.5456000000): norm = 22.1668663930, loss = 17.2413%, contribution = 2.0052%
Removed #23 (alfa = 0.1517000000): norm = 22.5131484066, loss = 15.9485%, contribution = 0.7078%
Removed #24 (alfa = 0.1517000000): norm = 18.2047184177, loss = 32.0338%, contribution = 1.5097%
Removed #25 (alfa = 0.5500000000): norm = 18.2076281291, loss = 32.0229%, contribution = 3.9667%
-----------------
-----------------
Atom: P     0
-----------------
  Block type: S
  Header: 12   1.00
    9.484000D+04           2.555090D-04
    1.422000D+04           1.981930D-03
    3.236000D+03           1.027600D-02
    9.171000D+02           4.148230D-02
    2.995000D+02           1.319840D-01
    1.081000D+02           3.086620D-01
    4.218000D+01           4.206470D-01
    1.728000D+01           2.228780D-01
    4.858000D+00           1.640350D-02
    1.818000D+00          -2.542550D-03
    3.372000D-01           7.480500D-04
    1.232000D-01          -3.309630D-04
Full norm: 0.9999998756
Removed # 1 (alfa = 94840.0000000000): norm = 0.9999886355, loss = 0.0011%, contribution = 3.1353%
Removed # 2 (alfa = 14220.0000000000): norm = 0.9996695656, loss = 0.0330%, contribution = 5.8598%
Removed # 3 (alfa = 3236.0000000000): norm = 0.9955733844, loss = 0.4426%, contribution = 10.0105%
Removed # 4 (alfa = 917.1000000000): norm = 0.9646740895, loss = 3.5326%, contribution = 15.6963%
Removed # 5 (alfa = 299.5000000000): norm = 0.8272550124, loss = 17.2745%, contribution = 21.5746%
Removed # 6 (alfa = 108.1000000000): norm = 0.5209735341, loss = 47.9026%, contribution = 23.4950%
Removed # 7 (alfa = 42.1800000000): norm = 0.3641202765, loss = 63.5880%, contribution = 15.8078%
Removed # 8 (alfa = 17.2800000000): norm = 0.6834047121, loss = 31.6595%, contribution = 4.2889%
Removed # 9 (alfa = 4.8580000000): norm = 0.9844917227, loss = 1.5508%, contribution = 0.1219%
Removed #10 (alfa = 1.8180000000): norm = 1.0013614074, loss = -0.1362%, contribution = 0.0090%
Removed #11 (alfa = 0.3372000000): norm = 0.9998776376, loss = 0.0122%, contribution = 0.0008%
Removed #12 (alfa = 0.1232000000): norm = 1.0000258648, loss = -0.0026%, contribution = 0.0002%
----------------------
Full norm after normalization: 1.0000000000
      9.484000D+04           2.555090D-04
      1.422000D+04           1.981930D-03
      3.236000D+03           1.027600D-02
      9.171000D+02           4.148230D-02
      2.995000D+02           1.319840D-01
      1.081000D+02           3.086620D-01
      4.218000D+01           4.206470D-01
      1.728000D+01           2.228780D-01
      4.858000D+00           1.640350D-02
      1.818000D+00          -2.542321D-03
      3.372000D-01           7.480500D-04
      1.232000D-01          -3.309332D-04
----------------------
  Block type: S
  Header: 12   1.00
    9.484000D+04          -6.969390D-05
    1.422000D+04          -5.352660D-04
    3.236000D+03          -2.837090D-03
    9.171000D+02          -1.139830D-02
    2.995000D+02          -3.929290D-02
    1.081000D+02          -9.963640D-02
    4.218000D+01          -1.979830D-01
    1.728000D+01          -1.148600D-01
    4.858000D+00           5.185950D-01
    1.818000D+00           6.018470D-01
    3.372000D-01           3.686120D-02
    1.232000D-01          -9.707590D-03
Full norm: 1.0000005142
Removed # 1 (alfa = 94840.0000000000): norm = 0.9999996821, loss = 0.0001%, contribution = 2.1813%
Removed # 2 (alfa = 14220.0000000000): norm = 0.9999763516, loss = 0.0024%, contribution = 4.0366%
Removed # 3 (alfa = 3236.0000000000): norm = 0.9996725761, loss = 0.0328%, contribution = 7.0493%
Removed # 4 (alfa = 917.1000000000): norm = 0.9974767873, loss = 0.2524%, contribution = 11.0007%
Removed # 5 (alfa = 299.5000000000): norm = 0.9881209510, loss = 1.1880%, contribution = 16.3825%
Removed # 6 (alfa = 108.1000000000): norm = 0.9780434119, loss = 2.1957%, contribution = 19.3444%
Removed # 7 (alfa = 42.1800000000): norm = 1.0365311003, loss = -3.6531%, contribution = 18.9770%
Removed # 8 (alfa = 17.2800000000): norm = 1.0841303735, loss = -8.4130%, contribution = 5.6376%
Removed # 9 (alfa = 4.8580000000): norm = 0.4149540667, loss = 58.5046%, contribution = 9.8274%
Removed #10 (alfa = 1.8180000000): norm = 0.2306480864, loss = 76.9352%, contribution = 5.4570%
Removed #11 (alfa = 0.3372000000): norm = 0.9611710043, loss = 3.8829%, contribution = 0.0945%
Removed #12 (alfa = 0.1232000000): norm = 1.0058940155, loss = -0.5893%, contribution = 0.0117%
----------------------
Full norm after normalization: 1.0000000000
      9.484000D+04          -6.969529D-05
      1.422000D+04          -5.352767D-04
      3.236000D+03          -2.837147D-03
      9.171000D+02          -1.139853D-02
      2.995000D+02          -3.929368D-02
      1.081000D+02          -9.963839D-02
      4.218000D+01          -1.979870D-01
      1.728000D+01          -1.148623D-01
      4.858000D+00           5.185950D-01
      1.818000D+00           6.018470D-01
      3.372000D-01           3.686120D-02
      1.232000D-01          -9.707784D-03
----------------------
  Block type: S
  Header: 12   1.00
    9.484000D+04           1.911990D-05
    1.422000D+04           1.472230D-04
    3.236000D+03           7.779120D-04
    9.171000D+02           3.145460D-03
    2.995000D+02           1.082000D-02
    1.081000D+02           2.799570D-02
    4.218000D+01           5.639780D-02
    1.728000D+01           3.581900D-02
    4.858000D+00          -1.933870D-01
    1.818000D+00          -3.720970D-01
    3.372000D-01           6.242460D-01
    1.232000D-01           5.517210D-01
Full norm: 1.0000001303
Removed # 1 (alfa = 94840.0000000000): norm = 1.0000000677, loss = 0.0000%, contribution = 1.8084%
Removed # 2 (alfa = 14220.0000000000): norm = 0.9999983059, loss = 0.0002%, contribution = 3.3552%
Removed # 3 (alfa = 3236.0000000000): norm = 0.9999754624, loss = 0.0025%, contribution = 5.8412%
Removed # 4 (alfa = 917.1000000000): norm = 0.9998096456, loss = 0.0190%, contribution = 9.1741%
Removed # 5 (alfa = 299.5000000000): norm = 0.9991140529, loss = 0.0886%, contribution = 13.6330%
Removed # 6 (alfa = 108.1000000000): norm = 0.9984237262, loss = 0.1576%, contribution = 16.4258%
Removed # 7 (alfa = 42.1800000000): norm = 1.0033138955, loss = -0.3314%, contribution = 16.3365%
Removed # 8 (alfa = 17.2800000000): norm = 1.0070918621, loss = -0.7092%, contribution = 5.3130%
Removed # 9 (alfa = 4.8580000000): norm = 0.9863383157, loss = 1.3662%, contribution = 11.0748%
Removed #10 (alfa = 1.8180000000): norm = 1.1939310630, loss = -19.3931%, contribution = 10.1957%
Removed #11 (alfa = 0.3372000000): norm = 0.3944178550, loss = 60.5582%, contribution = 4.8343%
Removed #12 (alfa = 0.1232000000): norm = 0.2928959044, loss = 70.7104%, contribution = 2.0079%
----------------------
Full norm after normalization: 1.0000000000
      9.484000D+04           1.911990D-05
      1.422000D+04           1.472230D-04
      3.236000D+03           7.779120D-04
      9.171000D+02           3.145460D-03
      2.995000D+02           1.082000D-02
      1.081000D+02           2.799570D-02
      4.218000D+01           5.639780D-02
      1.728000D+01           3.581900D-02
      4.858000D+00          -1.933927D-01
      1.818000D+00          -3.721080D-01
      3.372000D-01           6.242460D-01
      1.232000D-01           5.517210D-01
----------------------
  Block type: S
  Header: 1   1.00
    1.232000D-01           1.000000D+00
Only one primitive - nothing to reduce.
----------------------
Full norm after normalization: 1.0000000000
      1.232000D-01           1.000000D+00
----------------------
  Block type: P
  Header: 8   1.00
    3.705000D+02           3.950050D-03
    8.733000D+01           3.024920D-02
    2.759000D+01           1.295540D-01
    1.000000D+01           3.275940D-01
    3.825000D+00           4.569920D-01
    1.494000D+00           2.530860D-01
    3.921000D-01           1.687980D-02
    1.186000D-01          -2.070930D-03
Full norm: 1.1338243229
Removed # 1 (alfa = 370.5000000000): norm = 1.1323856743, loss = 0.1269%, contribution = 5.3800%
Removed # 2 (alfa = 87.3300000000): norm = 1.1081110949, loss = 2.2678%, contribution = 13.9373%
Removed # 3 (alfa = 27.5900000000): norm = 0.9576223767, loss = 15.5405%, contribution = 25.1540%
Removed # 4 (alfa = 10.0000000000): norm = 0.5988184264, loss = 47.1860%, contribution = 29.7118%
Removed # 5 (alfa = 3.8250000000): norm = 0.3980385370, loss = 64.8942%, contribution = 20.1593%
Removed # 6 (alfa = 1.4940000000): norm = 0.7540094968, loss = 33.4986%, contribution = 5.5160%
Removed # 7 (alfa = 0.3921000000): norm = 1.1173654348, loss = 1.4516%, contribution = 0.1349%
Removed # 8 (alfa = 0.1186000000): norm = 1.1348110092, loss = -0.0870%, contribution = 0.0068%
----------------------
!! Projection normalization failed: negative discriminant. Solving numerically...
Optimized s2 = 9.99999963 (error = 1.25e-01)
Full norm after normalization: 1.0000000000
      3.705000D+02           3.723597D-03
      8.733000D+01           2.851504D-02
      2.759000D+01           1.221268D-01
      1.000000D+01           3.088133D-01
      3.825000D+00           4.307930D-01
      1.494000D+00           2.385768D-01
      3.921000D-01           1.591209D-02
      1.186000D-01          -1.952205D-02
----------------------
  Block type: P
  Header: 8   1.00
    3.705000D+02          -9.598320D-04
    8.733000D+01          -7.111770D-03
    2.759000D+01          -3.271220D-02
    1.000000D+01          -7.957840D-02
    3.825000D+00          -1.350160D-01
    1.494000D+00          -9.105850D-03
    3.921000D-01           5.378020D-01
    1.186000D-01           5.690660D-01
Full norm: 1.0040728866
Removed # 1 (alfa = 370.5000000000): norm = 1.0040124078, loss = 0.0060%, contribution = 4.2919%
Removed # 2 (alfa = 87.3300000000): norm = 1.0031396595, loss = 0.0929%, contribution = 10.7575%
Removed # 3 (alfa = 27.5900000000): norm = 0.9992074678, loss = 0.4846%, contribution = 20.8513%
Removed # 4 (alfa = 10.0000000000): norm = 1.0030480041, loss = 0.1021%, contribution = 23.6949%
Removed # 5 (alfa = 3.8250000000): norm = 1.0553379690, loss = -5.1057%, contribution = 19.5532%
Removed # 6 (alfa = 1.4940000000): norm = 1.0119731209, loss = -0.7868%, contribution = 0.6515%
Removed # 7 (alfa = 0.3921000000): norm = 0.3357895100, loss = 66.5573%, contribution = 14.1101%
Removed # 8 (alfa = 0.1186000000): norm = 0.2507627832, loss = 75.0254%, contribution = 6.0896%
----------------------
!! Projection normalization failed: negative discriminant. Solving numerically...
Optimized s2 = 1.23051925 (error = 1.02e-03)
Full norm after normalization: 1.0000000000
      3.705000D+02          -1.180492D-03
      8.733000D+01          -8.746724D-03
      2.759000D+01          -4.023254D-02
      1.000000D+01          -9.787301D-02
      3.825000D+00          -1.660554D-01
      1.494000D+00          -1.119923D-02
      3.921000D-01           5.375288D-01
      1.186000D-01           5.687769D-01
----------------------
  Block type: P
  Header: 1   1.00
    1.186000D-01           1.000000D+00
Only one primitive - nothing to reduce.
----------------------
Full norm after normalization: 1.0000000000
      1.186000D-01           1.000000D+00
----------------------
  Block type: D
  Header: 1   1.00
    3.730000D-01           1.0000000
Only one primitive - nothing to reduce.
----------------------
Full norm after normalization: 1.0000000000
      3.730000D-01           1.000000D+00
----------------------
ALL joined
9.484000D+04           2.555090D-04
1.422000D+04           1.981930D-03
3.236000D+03           1.027600D-02
9.171000D+02           4.148230D-02
2.995000D+02           1.319840D-01
1.081000D+02           3.086620D-01
4.218000D+01           4.206470D-01
1.728000D+01           2.228780D-01
4.858000D+00           1.640350D-02
1.818000D+00          -2.542550D-03
3.372000D-01           7.480500D-04
1.232000D-01          -3.309630D-04
9.484000D+04          -6.969390D-05
1.422000D+04          -5.352660D-04
3.236000D+03          -2.837090D-03
9.171000D+02          -1.139830D-02
2.995000D+02          -3.929290D-02
1.081000D+02          -9.963640D-02
4.218000D+01          -1.979830D-01
1.728000D+01          -1.148600D-01
4.858000D+00           5.185950D-01
1.818000D+00           6.018470D-01
3.372000D-01           3.686120D-02
1.232000D-01          -9.707590D-03
9.484000D+04           1.911990D-05
1.422000D+04           1.472230D-04
3.236000D+03           7.779120D-04
9.171000D+02           3.145460D-03
2.995000D+02           1.082000D-02
1.081000D+02           2.799570D-02
4.218000D+01           5.639780D-02
1.728000D+01           3.581900D-02
4.858000D+00          -1.933870D-01
1.818000D+00          -3.720970D-01
3.372000D-01           6.242460D-01
1.232000D-01           5.517210D-01
1.232000D-01           1.000000D+00
3.705000D+02           3.950050D-03
8.733000D+01           3.024920D-02
2.759000D+01           1.295540D-01
1.000000D+01           3.275940D-01
3.825000D+00           4.569920D-01
1.494000D+00           2.530860D-01
3.921000D-01           1.687980D-02
1.186000D-01          -2.070930D-03
3.705000D+02          -9.598320D-04
8.733000D+01          -7.111770D-03
2.759000D+01          -3.271220D-02
1.000000D+01          -7.957840D-02
3.825000D+00          -1.350160D-01
1.494000D+00          -9.105850D-03
3.921000D-01           5.378020D-01
1.186000D-01           5.690660D-01
1.186000D-01           1.000000D+00
3.730000D-01           1.0000000

Full norm: 34.1779704451
Removed # 1 (alfa = 94840.0000000000): norm = 34.1779598375, loss = 0.0000%, contribution = 1.8169%
Removed # 2 (alfa = 14220.0000000000): norm = 34.1776546666, loss = 0.0009%, contribution = 3.3958%
Removed # 3 (alfa = 3236.0000000000): norm = 34.1736311892, loss = 0.0127%, contribution = 5.8011%
Removed # 4 (alfa = 917.1000000000): norm = 34.1416391783, loss = 0.1063%, contribution = 9.0962%
Removed # 5 (alfa = 299.5000000000): norm = 33.9826875883, loss = 0.5714%, contribution = 12.5026%
Removed # 6 (alfa = 108.1000000000): norm = 33.5227353333, loss = 1.9171%, contribution = 13.6156%
Removed # 7 (alfa = 42.1800000000): norm = 32.9674533554, loss = 3.5418%, contribution = 9.1607%
Removed # 8 (alfa = 17.2800000000): norm = 33.2809773538, loss = 2.6245%, contribution = 2.4855%
Removed # 9 (alfa = 4.8580000000): norm = 34.0801390435, loss = 0.2862%, contribution = 0.0706%
Removed #10 (alfa = 1.8180000000): norm = 34.1977339456, loss = -0.0578%, contribution = 0.0052%
Removed #11 (alfa = 0.3372000000): norm = 34.1698086429, loss = 0.0239%, contribution = 0.0004%
Removed #12 (alfa = 0.1232000000): norm = 34.1814471230, loss = -0.0102%, contribution = 0.0001%
Removed #13 (alfa = 94840.0000000000): norm = 34.1779733612, loss = -0.0000%, contribution = 0.4956%
Removed #14 (alfa = 14220.0000000000): norm = 34.1780570758, loss = -0.0003%, contribution = 0.9171%
Removed #15 (alfa = 3236.0000000000): norm = 34.1792056687, loss = -0.0036%, contribution = 1.6016%
Removed #16 (alfa = 917.1000000000): norm = 34.1885561188, loss = -0.0310%, contribution = 2.4994%
Removed #17 (alfa = 299.5000000000): norm = 34.2428379867, loss = -0.1898%, contribution = 3.7222%
Removed #18 (alfa = 108.1000000000): norm = 34.4301623724, loss = -0.7379%, contribution = 4.3951%
Removed #19 (alfa = 42.1800000000): norm = 34.8701943339, loss = -2.0254%, contribution = 4.3116%
Removed #20 (alfa = 17.2800000000): norm = 34.6790277078, loss = -1.4660%, contribution = 1.2809%
Removed #21 (alfa = 4.8580000000): norm = 31.3454745410, loss = 8.2875%, contribution = 2.2328%
Removed #22 (alfa = 1.8180000000): norm = 29.8635023613, loss = 12.6235%, contribution = 1.2398%
Removed #23 (alfa = 0.3372000000): norm = 33.7771175102, loss = 1.1728%, contribution = 0.0215%
Removed #24 (alfa = 0.1232000000): norm = 34.2800371103, loss = -0.2986%, contribution = 0.0027%
Removed #25 (alfa = 94840.0000000000): norm = 34.1779696468, loss = 0.0000%, contribution = 0.1360%
Removed #26 (alfa = 14220.0000000000): norm = 34.1779467181, loss = 0.0001%, contribution = 0.2523%
Removed #27 (alfa = 3236.0000000000): norm = 34.1776345668, loss = 0.0010%, contribution = 0.4392%
Removed #28 (alfa = 917.1000000000): norm = 34.1750949832, loss = 0.0084%, contribution = 0.6897%
Removed #29 (alfa = 299.5000000000): norm = 34.1606502335, loss = 0.0507%, contribution = 1.0250%
Removed #30 (alfa = 108.1000000000): norm = 34.1106830508, loss = 0.1969%, contribution = 1.2349%
Removed #31 (alfa = 42.1800000000): norm = 33.9951287978, loss = 0.5350%, contribution = 1.2282%
Removed #32 (alfa = 17.2800000000): norm = 34.0271133058, loss = 0.4414%, contribution = 0.3994%
Removed #33 (alfa = 4.8580000000): norm = 35.3719122040, loss = -3.4933%, contribution = 0.8326%
Removed #34 (alfa = 1.8180000000): norm = 37.2078284834, loss = -8.8649%, contribution = 0.7665%
Removed #35 (alfa = 0.3372000000): norm = 27.7561814443, loss = 18.7893%, contribution = 0.3635%
Removed #36 (alfa = 0.1232000000): norm = 28.6868673134, loss = 16.0662%, contribution = 0.1510%
Removed #37 (alfa = 0.1232000000): norm = 24.6735683960, loss = 27.8086%, contribution = 0.2736%
Removed #38 (alfa = 370.5000000000): norm = 34.1722162890, loss = 0.0168%, contribution = 0.4389%
Removed #39 (alfa = 87.3300000000): norm = 34.0996519989, loss = 0.2291%, contribution = 1.1370%
Removed #40 (alfa = 27.5900000000): norm = 33.7116101384, loss = 1.3645%, contribution = 2.0521%
Removed #41 (alfa = 10.0000000000): norm = 32.6708435012, loss = 4.4096%, contribution = 2.4239%
Removed #42 (alfa = 3.8250000000): norm = 31.4736724502, loss = 7.9124%, contribution = 1.6446%
Removed #43 (alfa = 1.4940000000): norm = 32.1719334592, loss = 5.8694%, contribution = 0.4500%
Removed #44 (alfa = 0.3921000000): norm = 33.9967656434, loss = 0.5302%, contribution = 0.0110%
Removed #45 (alfa = 0.1186000000): norm = 34.1995854163, loss = -0.0632%, contribution = 0.0006%
Removed #46 (alfa = 370.5000000000): norm = 34.1793733738, loss = -0.0041%, contribution = 0.1067%
Removed #47 (alfa = 87.3300000000): norm = 34.1966492885, loss = -0.0547%, contribution = 0.2673%
Removed #48 (alfa = 27.5900000000): norm = 34.3010338410, loss = -0.3601%, contribution = 0.5182%
Removed #49 (alfa = 10.0000000000): norm = 34.5764804714, loss = -1.1660%, contribution = 0.5888%
Removed #50 (alfa = 3.8250000000): norm = 35.0568723098, loss = -2.5715%, contribution = 0.4859%
Removed #51 (alfa = 1.4940000000): norm = 34.2525336749, loss = -0.2182%, contribution = 0.0162%
Removed #52 (alfa = 0.3921000000): norm = 28.6848142376, loss = 16.0722%, contribution = 0.3506%
Removed #53 (alfa = 0.1186000000): norm = 28.5634577729, loss = 16.4273%, contribution = 0.1513%
Removed #54 (alfa = 0.1186000000): norm = 24.7427154784, loss = 27.6062%, contribution = 0.2659%
Removed #55 (alfa = 0.3730000000): norm = 24.3680205660, loss = 28.7026%, contribution = 0.6280%
-----------------
